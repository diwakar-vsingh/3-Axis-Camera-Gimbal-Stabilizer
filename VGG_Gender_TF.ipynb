{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG_Gender_TF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diwakar-vsingh/3-Axis-Camera-Gimbal-Stabilizer/blob/master/VGG_Gender_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVt01tHIPJuN",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR_e9HS5w13l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import glob \n",
        "import pathlib\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import IPython\n",
        "\n",
        "from scipy.io import loadmat\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "_GPU = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JY_7YLUsQEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if _GPU:  \n",
        "  if gpu_info.find('failed') >= 0:\n",
        "    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "    print('and then re-execute this cell.')\n",
        "  else:\n",
        "    print(gpu_info)\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "  if gpu_info.find('failed') >= 0:\n",
        "    print('Running in on CPU')\n",
        "  else:\n",
        "    print(\"Runtime type: GPU\")\n",
        "    print('Select the Runtime > \"Change runtime type\" menu to None, ')\n",
        "    print('and then re-execute this cell.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI7I2bA8PLoz",
        "colab_type": "text"
      },
      "source": [
        "## VGG Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTRTQDW8wyCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the standalone generator model\n",
        "def VGG(image_shape, include_top=False):\n",
        "\n",
        "\t\"\"\"\n",
        "\tConstruct a VGG face descriptor model\n",
        "\t\"\"\"\n",
        " \n",
        "\t# Image Input\n",
        "\tinputs = tf.keras.Input(shape=image_shape, name=\"Input_Image\")\n",
        " \n",
        "\t## Convolutional layers\n",
        "\t# Layers 1-2\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=\"padd1_1\")(inputs)\n",
        "\tx = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, activation=\"relu\", name=\"conv1_1\")(x)\n",
        "\n",
        "\t# Layers 3-4\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=\"padd1_2\")(x)\n",
        "\tx = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, activation=\"relu\", name=\"conv1_2\")(x)\n",
        "\n",
        "\t# Layers 5\n",
        "\tx = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, name=\"pool1\")(x)\n",
        "\n",
        "\t# Layers 6-7\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=\"padd2_1\")(x)\n",
        "\tx = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=1, activation=\"relu\", name=\"conv2_1\")(x)\n",
        "\n",
        "\t# Layers 8-9\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=\"padd2_2\")(x)\n",
        "\tx = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=1, activation=\"relu\", name=\"conv2_2\")(x)\n",
        "\n",
        "\t# Layers 10\n",
        "\tx = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, name=\"pool2\")(x)\n",
        "\n",
        "\t# Layers 11-12\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=\"padd3_1\")(x)\n",
        "\tx = tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, activation=\"relu\", name=\"conv3_1\")(x)\n",
        "\n",
        "\t# Layers 13-14\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=\"padd3_2\")(x)\n",
        "\tx = tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, activation=\"relu\", name=\"conv3_2\")(x)\n",
        "\n",
        "\t# Layers 15-16\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=\"padd3_3\")(x)\n",
        "\tx = tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, activation=\"relu\", name=\"conv3_3\")(x)\n",
        "\n",
        "\t# Layers 17\n",
        "\tx = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, name=\"pool3\")(x)\n",
        "\n",
        "\t# Layers 18-19\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=\"padd4_1\")(x)\n",
        "\tx = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, activation=\"relu\", name=\"conv4_1\")(x)\n",
        "\n",
        "\t# Layers 20-21\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=\"padd4_2\")(x)\n",
        "\tx = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, activation=\"relu\", name=\"conv4_2\")(x)\n",
        "\t\n",
        "\t# Layers 22-23\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=\"padd4_3\")(x)\n",
        "\tx = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, activation=\"relu\", name=\"conv4_3\")(x)\n",
        "\n",
        "\t# Layers 24\n",
        "\tx = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, name=\"pool4\")(x)\n",
        "\n",
        "\t# Layers 25-26\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=\"padd5_1\")(x)\n",
        "\tx = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, activation=\"relu\", name=\"conv5_1\")(x)\n",
        "\n",
        "\t# Layers 27-28\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=\"padd5_2\")(x)\n",
        "\tx = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, activation=\"relu\", name=\"conv5_2\")(x)\n",
        "\n",
        "\t# Layers 29-30\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=\"padd5_3\")(x)\n",
        "\tx = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, activation=\"relu\", name=\"conv5_3\")(x)\n",
        "\n",
        "\t# Layers 31\n",
        "\tx = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, name=\"pool5\")(x)\n",
        " \n",
        "\t# Layers 32-33\n",
        "\tx = tf.keras.layers.Conv2D(filters=4096, kernel_size=7, strides=1, activation=\"relu\", name=\"fc6\")(x)\n",
        "\n",
        "\t# Layers 34\n",
        "\tx = tf.keras.layers.Conv2D(filters=4096, kernel_size=1, strides=1, activation=\"relu\", name=\"fc7\")(x)\n",
        "\t\n",
        "\tif include_top:\n",
        "\t\t# Layers 35-36\n",
        "\t\tx = tf.keras.layers.Conv2D(filters=2622, kernel_size=1, strides=1, activation=\"relu\", name=\"fc8\")(x)\n",
        "\t\tx = tf.keras.layers.Flatten(name=\"flatten\")(x)\n",
        " \n",
        "\t\t# Output Layer\t\n",
        "\t\tx = tf.keras.layers.Activation(activation=\"softmax\", name=\"prob\")(x)\n",
        "\n",
        "\telse:\n",
        "\t\t# Output Layer\t\n",
        "\t\tx = tf.keras.layers.Flatten(name=\"flatten\")(x)\n",
        " \n",
        "\t# Define model\n",
        "\tmodel = tf.keras.Model(inputs=inputs, outputs=x, name=\"VGG\")\n",
        " \n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNbLr8Y4w-hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the model\n",
        "base_model = VGG(image_shape=(224, 224, 3))\n",
        "\n",
        "# plot the model\n",
        "tf.keras.utils.plot_model(base_model, show_shapes=True, show_layer_names=True, dpi=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lSeAXPkSOSJ",
        "colab_type": "text"
      },
      "source": [
        "## Loading Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLiIiyOqql5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "URL = \"https://m-training.s3-us-west-2.amazonaws.com/dlchallenge/vgg_face_matconvnet.tar.gz\"\n",
        "path_to_zip = tf.keras.utils.get_file('vgg_face_matconvnet.tar', origin=URL, extract=True)\n",
        "PATH_MODEL = os.path.join(os.path.dirname(path_to_zip), 'vgg_face_matconvnet/data')\n",
        "data = loadmat(PATH_MODEL + '/vgg_face.mat', matlab_compatible=False, struct_as_record=False)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUH-eWapq3v3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the net object stores mat_struct object.\n",
        "net = data['net'][0][0]\n",
        "\n",
        "# Net object contains classes, layers and normalization sub objects. \n",
        "# Classes and normalization are discarded because weights are stored in layers.\n",
        "ref_model_layers = net.layers[0]\n",
        "print(\"Shape of reference model layer: \", ref_model_layers.shape)\n",
        "\n",
        "for layer in ref_model_layers:\n",
        "    print(layer[0][0].name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9Pa_4h1wmIG",
        "colab_type": "text"
      },
      "source": [
        "### Setting weights\n",
        "\n",
        "Just convolution and fully connected layers have weights. Trying to access weights for the rest of layers such as pooling or relu will cause exception. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqrVpVGFwjtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in base_model.layers:\n",
        "  layer_name = layer.name\n",
        "  try:\n",
        "    print(layer_name,\": \", layer.weights[0].shape)\n",
        "  except:\n",
        "    print(\"\",end='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj-opUgDxoLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(ref_model_layers.shape[0]):\n",
        "  ref_model_layer = ref_model_layers[i][0,0].name[0]\n",
        "  try:\n",
        "    weights = ref_model_layers[i][0,0].weights[0,0]\n",
        "    print(ref_model_layer,\": \",weights.shape)\n",
        "  except:\n",
        "    print(\"\",end='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJS8YjOgy4t-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model_layer_names = [layer.name for layer in base_model.layers]\n",
        "num_of_ref_model_layers = ref_model_layers.shape[0]\n",
        "for i in range(num_of_ref_model_layers):\n",
        "  ref_model_layer = ref_model_layers[i][0][0].name[0]\n",
        "  # print(ref_model_layer)\n",
        "  if ref_model_layer in base_model_layer_names:\n",
        "    if ref_model_layer.find(\"conv\") == 0 or ref_model_layer.find(\"fc\") == 0:\n",
        "      print(i, \". \", ref_model_layer)\n",
        "      \n",
        "      base_model_index = base_model_layer_names.index(ref_model_layer)\n",
        "      weights = ref_model_layers[i][0][0].weights[0,0]\n",
        "      bias = ref_model_layers[i][0][0].weights[0,1]\n",
        "\n",
        "      base_model.layers[base_model_index].set_weights([weights, bias[:,0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr1cdsFU04Mh",
        "colab_type": "text"
      },
      "source": [
        " Now base model has weights in Keras format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_Zd5T7rSuz9",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De9ScykZSyAo",
        "colab_type": "text"
      },
      "source": [
        "### Data Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSHvBdEuTU10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = \"https://s3.amazonaws.com/matroid-web/datasets/agegender_cleaned.tar.gz\"\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    fname=os.path.basename(_URL), \n",
        "    origin=_URL, \n",
        "    extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'combined')\n",
        "data_dir = pathlib.Path(PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5RFVbb4utdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64 if _GPU else 32\n",
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzPXiHRSzRwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*/*.jpg'), shuffle=True)\n",
        "for f in list_ds.take(5):\n",
        "  print(f.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-0SqE6bvwhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = np.array(sorted([item.name for item in pathlib.Path(os.path.join(data_dir, \"aligned\")).glob(\"*M\")]))\n",
        "\n",
        "def preprocess_image(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img)\n",
        "  img = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
        "  return img\n",
        "\n",
        "# Reads an image from a file, decodes it into a dense tensor, and resizes it to a fixed shape.\n",
        "def parse_image(file_path):\n",
        "\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  one_hot = tf.dtypes.cast(one_hot, tf.uint8)\n",
        "  label = tf.reduce_max(one_hot)\n",
        "\n",
        "  # load the raw data from the file as a string\n",
        "  image = tf.io.read_file(file_path)\n",
        "  image = preprocess_image(image)\n",
        "\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J_YydzIxgUZ",
        "colab_type": "text"
      },
      "source": [
        "### Map it over the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuwHAGRg2FFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_count = len(list_ds)\n",
        "print(image_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxWJXbuo2AZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_size = int(image_count * 0.15)\n",
        "train_ds = list_ds.skip(val_size)\n",
        "val_ds = list_ds.take(val_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcapL3ip21ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
        "print(tf.data.experimental.cardinality(val_ds).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sEENmaQ3Cod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "train_ds = train_ds.map(parse_image, num_parallel_calls=AUTOTUNE)\n",
        "val_ds = val_ds.map(parse_image, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR6q0roixiej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image, label in train_ds.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Budx6zhKGjFc",
        "colab_type": "text"
      },
      "source": [
        "### Configure dataset for performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG9R_ID_GLbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def configure_for_performance(ds):\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_ds = configure_for_performance(train_ds)\n",
        "val_ds = configure_for_performance(val_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwvguATyGs4M",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y_4a74DGrHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(4):\n",
        "  ax = plt.subplot(2, 2, i + 1)\n",
        "  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "  label = label_batch[i]\n",
        "  plt.title(label.numpy())\n",
        "  plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4VwLQjS2eS6",
        "colab_type": "text"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9klVlF0f2fwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(\n",
        "      factor=0.1, fill_mode=\"constant\")], \n",
        "      name=\"data_aug\")\n",
        "\n",
        "# Normalize input from (0, 255) to a range (-1., +1.), the normalization layer\n",
        "# does the following, outputs = (inputs - mean) / sqrt(var)\n",
        "norm_layer = tf.keras.layers.experimental.preprocessing.Normalization(name=\"Norm\")\n",
        "mean = np.array([127.5] * 3)\n",
        "var = mean ** 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKdRf5GQSg9O",
        "colab_type": "text"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT5c6J6cSmiZ",
        "colab_type": "text"
      },
      "source": [
        "### Freeze the convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjSVR9bwhDAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze base model\n",
        "base_model.trainable = False\n",
        "\n",
        "input = tf.keras.Input(shape=(224, 224, 3), name=\"input\")\n",
        "x = data_augmentation(input)\n",
        "x = norm_layer(x) # Scale inputs to [-1, +1]\n",
        "norm_layer.set_weights([mean, var])\n",
        "x = base_model(x, training=False)\n",
        "if _GPU:\n",
        "  x = tf.keras.layers.Dense(2048, activation=\"relu\", name=\"dense1\")(x)\n",
        "  x = tf.keras.layers.Dropout(rate=0.5, name=\"dropout1\")(x)\n",
        "  x = tf.keras.layers.Dense(1024, activation=\"relu\", name=\"dense2\")(x)\n",
        "  x = tf.keras.layers.Dropout(rate=0.5, name=\"dropout2\")(x)\n",
        "outputs = tf.keras.layers.Dense(1, name=\"output\")(x)\n",
        "\n",
        "model = tf.keras.Model(input, outputs, name=\"Gender_Classifier\")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un9hQC7bh0ce",
        "colab_type": "text"
      },
      "source": [
        "# Compile the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9iaqifkiTU1",
        "colab_type": "text"
      },
      "source": [
        "## Train and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx4bJKwF7sxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class History:\n",
        "  def __init__(self, smoothing_factor=0.0):\n",
        "    self.alpha = smoothing_factor\n",
        "    self.data = []\n",
        "  def append(self, value):\n",
        "    self.data.append( self.alpha*self.data[-1] + (1-self.alpha)*value if len(self.data)>0 else value )\n",
        "  def get(self):\n",
        "    return self.data\n",
        "\n",
        "@tf.function\n",
        "def train_step(image, label):\n",
        "  # Open a GradientTape.\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Forward pass.\n",
        "    logits = model(image, training=True)\n",
        "    # Compute the loss value for this batch.\n",
        "    loss_value = loss_fn(label, logits)\n",
        "    \n",
        "  # Get gradients of loss wrt the *trainable* weights.\n",
        "  grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "\n",
        "  # Update the weights of the model.\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "  # Compare predicted label to actual label\n",
        "  train_accuracy.update_state(label, logits)\n",
        "  return loss_value\n",
        "\n",
        "@tf.function\n",
        "def val_step(image, label):\n",
        "    val_logits = model(image, training=False)\n",
        "\n",
        "    # Compare predicted label to actual label\n",
        "    val_accuracy.update_state(label, val_logits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eFPcsYV4DkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 3 if _GPU else 1\n",
        "\n",
        "initial_learning_rate = 1e-1\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100,\n",
        "    decay_rate=0.95,\n",
        "    staircase=True)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "loss_history = History(smoothing_factor=0.99) # to record loss evolution\n",
        "acc_history = History(smoothing_factor=0.99) # to record accuracy evolution\n",
        "\n",
        "train_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "val_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "# Keep results for plotting\n",
        "train_accuracy_results = [0]\n",
        "val_accuracy_results = [0]\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(\"\\nStart of epoch %d\" % (epoch+1,))\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Iterate over the batches of a dataset.\n",
        "  for step, (images, labels) in enumerate(train_ds):\n",
        "    loss_value = train_step(images, labels)\n",
        "    \n",
        "    # Record the loss and accuracy evolution as a function of training \n",
        "    loss_history.append(loss_value.numpy().mean())\n",
        "    acc_history.append(train_accuracy.result())\n",
        "    \n",
        "    # Log every 200 batches.\n",
        "    temp = step % 200 if _GPU else step % 100\n",
        "    if temp == 0:\n",
        "      print(\"Training loss (for one batch) at step %d: %.4f\" % (step, float(loss_value)))\n",
        "      print(\"Seen so far: %d samples\" % ((step + 1) * BATCH_SIZE))\n",
        "  \n",
        "  for image_val, label_val in val_ds:\n",
        "    val_step(image_val, label_val)\n",
        "  \n",
        "  train_accuracy_results.append(train_accuracy.result())\n",
        "  val_accuracy_results.append(val_accuracy.result())\n",
        "  \n",
        "  # Display metrics at the end of each epoch.\n",
        "  print(\"Train Accuracy: {:.3%}, Val Accuracy: {:.3%}\".format(\n",
        "        train_accuracy.result(),\n",
        "        val_accuracy.result()))\n",
        "  print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
        "\n",
        "  # Reset training metrics at the end of each epoch\n",
        "  train_accuracy.reset_states()\n",
        "  val_accuracy.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cex3HZ3F_26G",
        "colab_type": "text"
      },
      "source": [
        "## Visualize the loss function over time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hj2MJXlfkLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(2, sharex=True, figsize=(8, 8))\n",
        "\n",
        "axes[0].set_ylabel(\"Train Loss\", fontsize=14)\n",
        "axes[0].plot(loss_history.get())\n",
        "\n",
        "axes[1].set_ylabel(\"Train Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Step\", fontsize=14)\n",
        "axes[1].plot(acc_history.get())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLNCe8rt_6VE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(train_accuracy_results, label=\"Train Acc\")\n",
        "plt.plot(val_accuracy_results, label=\"Val Acc\")\n",
        "plt.ylabel(\"Accuracy\", fontsize=14)\n",
        "plt.xlabel(\"Epoch\", fontsize=14)\n",
        "plt.grid(\"On\")\n",
        "plt.ylim([0, 1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm6LgaRyIXM1",
        "colab_type": "text"
      },
      "source": [
        "### Visualize exponential learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isKScxeYznsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_learning_rate = 1e-1\n",
        "decay_rate = 0.95\n",
        "decay_steps = 100\n",
        "decayed_learning_rate = lambda step: initial_learning_rate * decay_rate ** (step / decay_steps)\n",
        "\n",
        "steps = np.linspace(0, 2700, 1000)\n",
        "lr = decayed_learning_rate(steps)*1000\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(steps, lr)\n",
        "plt.title(\"Learning rate schedule\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6NofcizHEPx",
        "colab_type": "text"
      },
      "source": [
        "## Save the entire model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c04fDq2THGZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the entire model to a HDF5 file.\n",
        "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
        "model.save('VGG_GENDER.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5wTjj2WLJEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "new_model = tf.keras.models.load_model('VGG_GENDER.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_FSCzpJSlM6",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate on test image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLAkzfulSk1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load test image\n",
        "img_path = os.path.join(os.path.dirname(PATH_MODEL), \"ak.jpg\") \n",
        "image = tf.io.read_file(img_path)\n",
        "image = preprocess_image(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jkeARkXENYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate image type\n",
        "logits = model(image, training=False)\n",
        "label = tf.constant([1])\n",
        "loss_value = loss_fn(label, logits)\n",
        "\n",
        "# Apply a sigmoid since our model returns logits\n",
        "pred = tf.nn.sigmoid(logits)\n",
        "predictions = tf.where(pred < 0.5, 0, 1)\n",
        "predictions = tf.squeeze(predictions)\n",
        "predictions = np.where(predictions.numpy() < 0.5, \"Female\", \"Male\")\n",
        "label = np.where(label.numpy()[0] == 0, \"Female\", \"Male\")\n",
        "print('Predictions:', predictions)\n",
        "print('Labels:', label)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(image.numpy().astype(\"uint8\"))\n",
        "plt.title(predictions)\n",
        "plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}